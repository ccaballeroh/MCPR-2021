{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03Experiments.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python [conda env:mcpr2021]",
      "language": "python",
      "name": "conda-env-mcpr2021-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccaballeroh/MCPR-2021/blob/main/03Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDyOrAL_uaKE"
      },
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DHctFzuaKJ"
      },
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    ROOT = Path(r\"./drive/My Drive/MCPR-2021\")\n",
        "    sys.path.insert(0,f\"{ROOT}/\")\n",
        "else:\n",
        "    from helper import ROOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BvwbPV7WH1Z"
      },
      "source": [
        "# Experiments\n",
        "\n",
        "This notebook contains the code to reproduce the results of the experiments on the corpora. The experiments consist on doing a 10-fold cross-validation using four different classifiers: a linear support vector machine, a logistic regression, a naïve bayes classifier, and a decision tree, for all the feature sets obtained on [02Feature Extraction](./02Feature_Extraction.ipynb). All the classifiers were trained using the default values (except the support vector machine which showed improvement for having the data with standard deviation $\\sigma = 1$). The results are saved in a `DataFrame` for convenience and later saved to disk in $\\LaTeX$ format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05J6RsRnWH1a"
      },
      "source": [
        "## Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2HB1lIjAf7b"
      },
      "source": [
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from helper.analysis import JSON_FOLDER, get_dataset_from_json\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCXnhgXNAON"
      },
      "source": [
        "## Experiments for the Ibsen corpus\r\n",
        "\r\n",
        "In this section, we perform two kinds of experiments:\r\n",
        "\r\n",
        "1. We test the classifiers with two separate corpora: the parallel and the non-parallel.\r\n",
        "1. We test the classifiers with the mixed corpora (i.e., we train with the parallel and test on the non-pararallel and _vice versa_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdEa73lfCGXY"
      },
      "source": [
        "features_files = [\n",
        "    file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Ibsen\")\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noquTj4nWH1d"
      },
      "source": [
        "### 1. Experiments with the parallel and the non-parallel corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwMKE7KtAf7w"
      },
      "source": [
        "results_all_corpora = {}\n",
        "\n",
        "for corpus in [\"Ghosts\", \"Others\"]:\n",
        "\n",
        "    indexes = []  # file names as indices\n",
        "    cols = [\"Dimension\", \"SVC\", \"Naïve Bayes\", \"Decision Tree\", \"Logistic Regression\"]\n",
        "    results = []  # Where to hold the results per corpus\n",
        "\n",
        "    for file in [file for file in features_files if corpus in file.name]:\n",
        "\n",
        "        # Import data from JSON files\n",
        "        X_dict, y_str = get_dataset_from_json(file)\n",
        "\n",
        "        # Transformers to numpy arrays\n",
        "        dict_vect = DictVectorizer(sparse=True)\n",
        "        encoder = LabelEncoder()\n",
        "\n",
        "        # Numeric conversion\n",
        "        X = dict_vect.fit_transform(X_dict,)\n",
        "        y = encoder.fit_transform(y_str)\n",
        "\n",
        "        # Number of features\n",
        "        k = 25  # number of features to select\n",
        "        dimension = k  # comment out this line and uncomment next for full data set\n",
        "       # dimension = X.shape[1]\n",
        "\n",
        "        # K-fold to ingest cross-validation\n",
        "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "        # Models\n",
        "\n",
        "        ## SVM\n",
        "        svm_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"scaler\", StandardScaler(with_mean=False)),\n",
        "                (\"scv\", LinearSVC(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_svm = cross_val_score(svm_model, X, y, cv=kf)\n",
        "\n",
        "        ## Logistic regresssion\n",
        "        log_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"scaler\", StandardScaler(with_mean=False)),\n",
        "                (\"lrc\", LogisticRegression(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_log = cross_val_score(log_model, X, y, cv=kf)\n",
        "\n",
        "        ## Naïve Bayes\n",
        "        nb_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"nb\", MultinomialNB()),\n",
        "            ]\n",
        "        )\n",
        "        cv_nb = cross_val_score(nb_model, X, y, cv=kf)\n",
        "\n",
        "        ## Decision Tree\n",
        "        dt_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_dt = cross_val_score(dt_model, X, y, cv=kf)\n",
        "\n",
        "        # Results of cross-val for each feature set\n",
        "        result_per_featureset = [\n",
        "            dimension,\n",
        "            cv_svm.mean(),\n",
        "            cv_nb.mean(),\n",
        "            cv_dt.mean(),\n",
        "            cv_log.mean(),\n",
        "        ]\n",
        "\n",
        "        # Overall results for each author\n",
        "        results.append(result_per_featureset)\n",
        "        indexes.append(\" \".join(file.stem.split(\"_\")[2:]))  # features from file name\n",
        "\n",
        "    # All features for all authors\n",
        "    results_all_corpora[corpus] = pd.DataFrame(\n",
        "        np.array(results), index=indexes, columns=cols\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLROCvb5Af71"
      },
      "source": [
        "#### Save results $\\LaTeX$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Fmr3iM0nNAOh",
        "outputId": "afc6b732-aa12-491d-9a34-3b33580665ae"
      },
      "source": [
        "results_all_corpora[\"Ghosts\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.955</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.935</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.935</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.445</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension    SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.680        0.815          0.610   \n",
              "1grams punct          25.0  0.900        0.815          0.745   \n",
              "2grams                25.0  0.755        0.755          0.720   \n",
              "2gramsPOS             25.0  0.620        0.515          0.575   \n",
              "2gramsPOS punct       25.0  1.000        1.000          0.935   \n",
              "2grams punct          25.0  0.940        0.980          0.955   \n",
              "3grams                25.0  0.595        0.600          0.470   \n",
              "3gramsPOS             25.0  0.240        0.225          0.370   \n",
              "3gramsPOS punct       25.0  1.000        1.000          0.935   \n",
              "3grams punct          25.0  1.000        1.000          0.935   \n",
              "cohesive              25.0  0.475        0.615          0.610   \n",
              "cohesive punct        25.0  0.675        0.615          0.635   \n",
              "syntactic n2          25.0  0.445        0.565          0.835   \n",
              "syntactic n3          25.0  0.515        0.555          0.530   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                         0.840  \n",
              "1grams punct                   0.855  \n",
              "2grams                         0.780  \n",
              "2gramsPOS                      0.595  \n",
              "2gramsPOS punct                0.975  \n",
              "2grams punct                   0.980  \n",
              "3grams                         0.575  \n",
              "3gramsPOS                      0.280  \n",
              "3gramsPOS punct                1.000  \n",
              "3grams punct                   1.000  \n",
              "cohesive                       0.535  \n",
              "cohesive punct                 0.595  \n",
              "syntactic n2                   0.460  \n",
              "syntactic n3                   0.535  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "jKoYiCXdNAOl",
        "outputId": "35f6588d-f565-4ec0-ebbe-56576376ab90"
      },
      "source": [
        "results_all_corpora[\"Others\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.890523</td>\n",
              "      <td>0.919281</td>\n",
              "      <td>0.803268</td>\n",
              "      <td>0.902288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.918627</td>\n",
              "      <td>0.797712</td>\n",
              "      <td>0.866013</td>\n",
              "      <td>0.930392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.930719</td>\n",
              "      <td>0.931046</td>\n",
              "      <td>0.814706</td>\n",
              "      <td>0.942484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.838235</td>\n",
              "      <td>0.855882</td>\n",
              "      <td>0.728758</td>\n",
              "      <td>0.862092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.900980</td>\n",
              "      <td>0.907190</td>\n",
              "      <td>0.808497</td>\n",
              "      <td>0.894771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.873856</td>\n",
              "      <td>0.677451</td>\n",
              "      <td>0.838562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.959477</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.819608</td>\n",
              "      <td>0.832026</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.808497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.843464</td>\n",
              "      <td>0.849020</td>\n",
              "      <td>0.837255</td>\n",
              "      <td>0.890196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.889869</td>\n",
              "      <td>0.919281</td>\n",
              "      <td>0.814706</td>\n",
              "      <td>0.925163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.908170</td>\n",
              "      <td>0.925163</td>\n",
              "      <td>0.867320</td>\n",
              "      <td>0.924837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.890523     0.919281       0.803268   \n",
              "1grams punct          25.0  0.918627     0.797712       0.866013   \n",
              "2grams                25.0  0.930719     0.931046       0.814706   \n",
              "2gramsPOS             25.0  0.838235     0.855882       0.728758   \n",
              "2gramsPOS punct       25.0  0.988235     0.994118       0.982680   \n",
              "2grams punct          25.0  0.988235     0.994118       0.982680   \n",
              "3grams                25.0  0.900980     0.907190       0.808497   \n",
              "3gramsPOS             25.0  0.844444     0.873856       0.677451   \n",
              "3gramsPOS punct       25.0  0.994118     0.959477       0.970588   \n",
              "3grams punct          25.0  0.988235     0.994118       0.982680   \n",
              "cohesive              25.0  0.819608     0.832026       0.711111   \n",
              "cohesive punct        25.0  0.843464     0.849020       0.837255   \n",
              "syntactic n2          25.0  0.889869     0.919281       0.814706   \n",
              "syntactic n3          25.0  0.908170     0.925163       0.867320   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.902288  \n",
              "1grams punct                0.930392  \n",
              "2grams                      0.942484  \n",
              "2gramsPOS                   0.862092  \n",
              "2gramsPOS punct             0.994118  \n",
              "2grams punct                0.994118  \n",
              "3grams                      0.894771  \n",
              "3gramsPOS                   0.838562  \n",
              "3gramsPOS punct             0.994118  \n",
              "3grams punct                0.988235  \n",
              "cohesive                    0.808497  \n",
              "cohesive punct              0.890196  \n",
              "syntactic n2                0.925163  \n",
              "syntactic n3                0.924837  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ES4St_IAf76"
      },
      "source": [
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "for corpus in [\"Ghosts\", \"Others\"]:\n",
        "    df = results_all_corpora[corpus].sort_index()\n",
        "    \n",
        "    latex = df.to_latex(float_format=lambda x: '%.4f' % x)\n",
        "    with open(RESULTS_FOLDER/(corpus + \".tex\"), \"w\") as f:\n",
        "        f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dV9X8zJNAPE"
      },
      "source": [
        "### 2. Experiments with Mixed Corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhresNicNAPI"
      },
      "source": [
        "def run_all_classifiers(file_train: Path, file_test: Path, k: int = 25):\n",
        "\n",
        "    X_train_dict, y_train_str = get_dataset_from_json(file_train)\n",
        "    X_test_dict, y_test_str = get_dataset_from_json(file_test)\n",
        "\n",
        "    dict_vectorizer = DictVectorizer(sparse=True)\n",
        "    encoder = LabelEncoder()\n",
        "\n",
        "    X_train, y_train = (\n",
        "        dict_vectorizer.fit_transform(X_train_dict),\n",
        "        encoder.fit_transform(y_train_str),\n",
        "    )\n",
        "\n",
        "    X_test, y_test = (\n",
        "        dict_vectorizer.transform(X_test_dict),\n",
        "        encoder.transform(y_test_str),\n",
        "    )\n",
        "\n",
        "    # Shuffle\n",
        "    X_train_, y_train_ = shuffle(\n",
        "        X_train, y_train, random_state=24\n",
        "    )\n",
        "    # Models\n",
        "    svm_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"scv\", LinearSVC(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    log_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"lr\", LogisticRegression(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    nb_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"nb\", MultinomialNB()),\n",
        "        ])\n",
        "    \n",
        "    dt_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "        ]) \n",
        "    \n",
        "    \n",
        "\n",
        "    svm_model.fit(X_train_, y_train_)\n",
        "    log_model.fit(X_train_, y_train_)\n",
        "    nb_model.fit(X_train_, y_train_)\n",
        "    dt_model.fit(X_train_, y_train_)\n",
        "\n",
        "    return [\n",
        "        k,\n",
        "        accuracy_score(y_test, svm_model.predict(X_test)),\n",
        "        accuracy_score(y_test, log_model.predict(X_test)),\n",
        "        accuracy_score(y_test, nb_model.predict(X_test)),\n",
        "        accuracy_score(y_test, dt_model.predict(X_test)),\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhqVcZJ-NAPM"
      },
      "source": [
        "from helper.analysis import JSON_FOLDER, get_dataset_from_json\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from helper import ROOT\n",
        "\n",
        "features_files = [file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Ibsen\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVl_Ny2NAPQ"
      },
      "source": [
        "ghosts = [file for file in features_files if \"Ghosts\" in file.stem]\n",
        "others = [file for file in features_files if not \"Ghosts\" in file.stem]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwYZKVe-NAPX"
      },
      "source": [
        "features = [(train, test) for train, test in zip(ghosts, others) if \" \".join(train.stem.split(\"_\")[2:]) == \" \".join(test.stem.split(\"_\")[2:])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOP8WGNsNAPb"
      },
      "source": [
        "columns = [\n",
        "    \"Dimension\",\n",
        "    \"SVC\",\n",
        "    \"Naïve Bayes\",\n",
        "    \"Decision Tree\",\n",
        "    \"Logistic Regression\",\n",
        "]\n",
        "\n",
        "indexes = [\" \".join(train.stem.split(\"_\")[2:]) for train, test in features]\n",
        "\n",
        "results_parallel = [run_all_classifiers(train, test) for train, test in features]\n",
        "results_parallel_df = pd.DataFrame(\n",
        "    np.array(results_parallel), index=indexes, columns=columns\n",
        ")\n",
        "\n",
        "results_inverse = [run_all_classifiers(train, test) for test, train in features]\n",
        "results_inverse_df = pd.DataFrame(\n",
        "    np.array(results_inverse), index=indexes, columns=columns\n",
        ")\n",
        "\n",
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "d = {\"parallel\": results_parallel_df, \"inverse\": results_inverse_df}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVf2LsENXR35"
      },
      "source": [
        "#### Save results to $\\LaTeX$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "31cPrTwINAPe",
        "outputId": "a9040c88-63b1-418b-d152-9ea462c3ae79"
      },
      "source": [
        "d[\"parallel\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.664740</td>\n",
              "      <td>0.722543</td>\n",
              "      <td>0.780347</td>\n",
              "      <td>0.537572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.393064</td>\n",
              "      <td>0.439306</td>\n",
              "      <td>0.861272</td>\n",
              "      <td>0.653179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.554913</td>\n",
              "      <td>0.566474</td>\n",
              "      <td>0.606936</td>\n",
              "      <td>0.514451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.595376</td>\n",
              "      <td>0.670520</td>\n",
              "      <td>0.589595</td>\n",
              "      <td>0.664740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.947977</td>\n",
              "      <td>0.930636</td>\n",
              "      <td>0.959538</td>\n",
              "      <td>0.780347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.780347</td>\n",
              "      <td>0.774566</td>\n",
              "      <td>0.942197</td>\n",
              "      <td>0.797688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.630058</td>\n",
              "      <td>0.687861</td>\n",
              "      <td>0.653179</td>\n",
              "      <td>0.462428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.537572</td>\n",
              "      <td>0.537572</td>\n",
              "      <td>0.554913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.976879</td>\n",
              "      <td>0.971098</td>\n",
              "      <td>0.947977</td>\n",
              "      <td>0.791908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.942197</td>\n",
              "      <td>0.971098</td>\n",
              "      <td>0.988439</td>\n",
              "      <td>0.768786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.583815</td>\n",
              "      <td>0.572254</td>\n",
              "      <td>0.647399</td>\n",
              "      <td>0.578035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.595376</td>\n",
              "      <td>0.624277</td>\n",
              "      <td>0.618497</td>\n",
              "      <td>0.612717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.647399</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.589595</td>\n",
              "      <td>0.572254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.572254</td>\n",
              "      <td>0.572254</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.497110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.664740     0.722543       0.780347   \n",
              "1grams punct          25.0  0.393064     0.439306       0.861272   \n",
              "2grams                25.0  0.554913     0.566474       0.606936   \n",
              "2gramsPOS             25.0  0.595376     0.670520       0.589595   \n",
              "2gramsPOS punct       25.0  0.947977     0.930636       0.959538   \n",
              "2grams punct          25.0  0.780347     0.774566       0.942197   \n",
              "3grams                25.0  0.630058     0.687861       0.653179   \n",
              "3gramsPOS             25.0  0.531792     0.537572       0.537572   \n",
              "3gramsPOS punct       25.0  0.976879     0.971098       0.947977   \n",
              "3grams punct          25.0  0.942197     0.971098       0.988439   \n",
              "cohesive              25.0  0.583815     0.572254       0.647399   \n",
              "cohesive punct        25.0  0.595376     0.624277       0.618497   \n",
              "syntactic n2          25.0  0.647399     0.641618       0.589595   \n",
              "syntactic n3          25.0  0.572254     0.572254       0.531792   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.537572  \n",
              "1grams punct                0.653179  \n",
              "2grams                      0.514451  \n",
              "2gramsPOS                   0.664740  \n",
              "2gramsPOS punct             0.780347  \n",
              "2grams punct                0.797688  \n",
              "3grams                      0.462428  \n",
              "3gramsPOS                   0.554913  \n",
              "3gramsPOS punct             0.791908  \n",
              "3grams punct                0.768786  \n",
              "cohesive                    0.578035  \n",
              "cohesive punct              0.612717  \n",
              "syntactic n2                0.572254  \n",
              "syntactic n3                0.497110  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "9za-Yh67NAPh",
        "outputId": "7abc1d35-9e0e-43b1-d635-ced5003da8a9"
      },
      "source": [
        "d[\"inverse\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.653061</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.612245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.653061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.510204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.979592</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.469388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.816327</td>\n",
              "      <td>0.836735</td>\n",
              "      <td>0.959184</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.632653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.591837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.551020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.632653     0.653061       0.551020   \n",
              "1grams punct          25.0  0.632653     0.612245       0.612245   \n",
              "2grams                25.0  0.734694     0.734694       0.591837   \n",
              "2gramsPOS             25.0  0.591837     0.591837       0.571429   \n",
              "2gramsPOS punct       25.0  0.877551     0.877551       0.979592   \n",
              "2grams punct          25.0  0.918367     0.857143       0.897959   \n",
              "3grams                25.0  0.530612     0.530612       0.510204   \n",
              "3gramsPOS             25.0  0.591837     0.551020       0.551020   \n",
              "3gramsPOS punct       25.0  0.816327     0.836735       0.959184   \n",
              "3grams punct          25.0  0.897959     0.877551       0.918367   \n",
              "cohesive              25.0  0.551020     0.551020       0.591837   \n",
              "cohesive punct        25.0  0.571429     0.571429       0.612245   \n",
              "syntactic n2          25.0  0.612245     0.571429       0.551020   \n",
              "syntactic n3          25.0  0.612245     0.591837       0.571429   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.612245  \n",
              "1grams punct                0.653061  \n",
              "2grams                      0.571429  \n",
              "2gramsPOS                   0.510204  \n",
              "2gramsPOS punct             0.836735  \n",
              "2grams punct                0.836735  \n",
              "3grams                      0.428571  \n",
              "3gramsPOS                   0.469388  \n",
              "3gramsPOS punct             1.000000  \n",
              "3grams punct                0.836735  \n",
              "cohesive                    0.632653  \n",
              "cohesive punct              0.571429  \n",
              "syntactic n2                0.591837  \n",
              "syntactic n3                0.551020  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ihGGWhGNAPl"
      },
      "source": [
        "for exp in d:\n",
        "    df = d[exp].sort_index()\n",
        "    \n",
        "    latex = df.to_latex(float_format=lambda x: \"%.4f\" % x)\n",
        "\n",
        "    with open((RESULTS_FOLDER / f\"{exp}.tex\"), \"w\") as f:\n",
        "        f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X520FoTvXR36"
      },
      "source": [
        "## Experiments for the *Quixote* corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgeveuuoXR37"
      },
      "source": [
        "features_files = [\n",
        "    file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Quixote\")\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJU2mKsYXR37"
      },
      "source": [
        "results_all_corpora = {}\n",
        "\n",
        "author = \"Quixote\"\n",
        "\n",
        "indexes = []  # file names as indices\n",
        "cols = [\"Dimension\", \"SVC\", \"Naïve Bayes\", \"Decision Tree\", \"Logistic Regression\"]\n",
        "results = []  # Where to hold the results\n",
        "\n",
        "for file in features_files:\n",
        "\n",
        "    # Import data from JSON files\n",
        "    X_dict, y_str = get_dataset_from_json(file)\n",
        "\n",
        "    # Transformers to numpy arrays\n",
        "    dict_vect = DictVectorizer(sparse=True)\n",
        "    encoder = LabelEncoder()\n",
        "\n",
        "    # Numeric conversion\n",
        "    X = dict_vect.fit_transform(X_dict,)\n",
        "    y = encoder.fit_transform(y_str)\n",
        "\n",
        "    # Number of features\n",
        "    k = 25  # number of features to select\n",
        "    dimension = k  # comment out this line an uncomment next one for full dimension\n",
        "   # dimension = X.shape[1]\n",
        "\n",
        "    # K-fold to ingest cross-validation\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    # Models\n",
        "\n",
        "    ## SVM\n",
        "    svm_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"scv\", LinearSVC(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "    cv_svm = cross_val_score(svm_model, X, y, cv=kf)\n",
        "\n",
        "    ## Logistic regresssion\n",
        "    log_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"lrc\", LogisticRegression(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "    cv_log = cross_val_score(log_model, X, y, cv=kf)\n",
        "\n",
        "    ## Naïve Bayes\n",
        "    nb_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"nb\", MultinomialNB()),]\n",
        "    )\n",
        "    cv_nb = cross_val_score(nb_model, X, y, cv=kf)\n",
        "\n",
        "    ## Decision Tree\n",
        "    dt_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "    cv_dt = cross_val_score(dt_model, X, y, cv=kf)\n",
        "\n",
        "    # Results of cross-val for each feature set\n",
        "    result_per_featureset = [\n",
        "        dimension,\n",
        "        cv_svm.mean(),\n",
        "        cv_nb.mean(),\n",
        "        cv_dt.mean(),\n",
        "        cv_log.mean(),\n",
        "    ]\n",
        "\n",
        "    # Overall results for each author\n",
        "    results.append(result_per_featureset)\n",
        "    indexes.append(\" \".join(file.stem.split(\"_\")[1:]))  # features from file name\n",
        "\n",
        "# All features for all authors\n",
        "results_all_corpora[author] = pd.DataFrame(\n",
        "    np.array(results), index=indexes, columns=cols\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KKrio9OXR37"
      },
      "source": [
        "#### Save results to $\\LaTeX$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UyLvm9JXR38",
        "outputId": "38576277-b0b5-4b03-84c0-1b7e45a93cf5"
      },
      "source": [
        "results_all_corpora[\"Quixote\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.981508</td>\n",
              "      <td>0.957824</td>\n",
              "      <td>0.923400</td>\n",
              "      <td>0.973613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.968350</td>\n",
              "      <td>0.978876</td>\n",
              "      <td>0.949644</td>\n",
              "      <td>0.970910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.960171</td>\n",
              "      <td>0.952205</td>\n",
              "      <td>0.867852</td>\n",
              "      <td>0.965647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.833001</td>\n",
              "      <td>0.804125</td>\n",
              "      <td>0.581081</td>\n",
              "      <td>0.843599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.965647</td>\n",
              "      <td>0.957681</td>\n",
              "      <td>0.949858</td>\n",
              "      <td>0.976245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.984211</td>\n",
              "      <td>0.981508</td>\n",
              "      <td>0.984139</td>\n",
              "      <td>0.984211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.880797</td>\n",
              "      <td>0.857112</td>\n",
              "      <td>0.814651</td>\n",
              "      <td>0.880797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.820199</td>\n",
              "      <td>0.812304</td>\n",
              "      <td>0.603058</td>\n",
              "      <td>0.841252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.968350</td>\n",
              "      <td>0.973613</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.965718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.986842</td>\n",
              "      <td>0.973471</td>\n",
              "      <td>0.973542</td>\n",
              "      <td>0.978805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.891323</td>\n",
              "      <td>0.906899</td>\n",
              "      <td>0.777383</td>\n",
              "      <td>0.896657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.959957</td>\n",
              "      <td>0.957468</td>\n",
              "      <td>0.817496</td>\n",
              "      <td>0.981294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.949716</td>\n",
              "      <td>0.939189</td>\n",
              "      <td>0.880868</td>\n",
              "      <td>0.960384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.854125</td>\n",
              "      <td>0.848933</td>\n",
              "      <td>0.740754</td>\n",
              "      <td>0.859388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.981508     0.957824       0.923400   \n",
              "1grams punct          25.0  0.968350     0.978876       0.949644   \n",
              "2grams                25.0  0.960171     0.952205       0.867852   \n",
              "2gramsPOS             25.0  0.833001     0.804125       0.581081   \n",
              "2gramsPOS punct       25.0  0.965647     0.957681       0.949858   \n",
              "2grams punct          25.0  0.984211     0.981508       0.984139   \n",
              "3grams                25.0  0.880797     0.857112       0.814651   \n",
              "3gramsPOS             25.0  0.820199     0.812304       0.603058   \n",
              "3gramsPOS punct       25.0  0.968350     0.973613       0.957895   \n",
              "3grams punct          25.0  0.986842     0.973471       0.973542   \n",
              "cohesive              25.0  0.891323     0.906899       0.777383   \n",
              "cohesive punct        25.0  0.959957     0.957468       0.817496   \n",
              "syntactic n2          25.0  0.949716     0.939189       0.880868   \n",
              "syntactic n3          25.0  0.854125     0.848933       0.740754   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.973613  \n",
              "1grams punct                0.970910  \n",
              "2grams                      0.965647  \n",
              "2gramsPOS                   0.843599  \n",
              "2gramsPOS punct             0.976245  \n",
              "2grams punct                0.984211  \n",
              "3grams                      0.880797  \n",
              "3gramsPOS                   0.841252  \n",
              "3gramsPOS punct             0.965718  \n",
              "3grams punct                0.978805  \n",
              "cohesive                    0.896657  \n",
              "cohesive punct              0.981294  \n",
              "syntactic n2                0.960384  \n",
              "syntactic n3                0.859388  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chuuV2fXR39"
      },
      "source": [
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "df = results_all_corpora[author].sort_index()\n",
        "\n",
        "latex = df.to_latex(float_format=lambda x: \"%.4f\" % x)\n",
        "with open(RESULTS_FOLDER / (author + \".tex\"), \"w\") as f:\n",
        "    f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}