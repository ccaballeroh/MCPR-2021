{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03Experiments_Ibsen.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python [conda env:mcpr2021]",
      "language": "python",
      "name": "conda-env-mcpr2021-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccaballeroh/MCPR-2021/blob/main/03Experiments_Ibsen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDyOrAL_uaKE"
      },
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DHctFzuaKJ",
        "outputId": "b3756a1f-05e2-448f-9338-d893809e6630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    ROOT = Path(r\"./drive/My Drive/Translator-Attribution\")\n",
        "    sys.path.insert(0,f\"{ROOT}/\")\n",
        "else:\n",
        "    from helper import ROOT"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BvwbPV7WH1Z"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05J6RsRnWH1a"
      },
      "source": [
        "## Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2HB1lIjAf7b",
        "outputId": "5c8d72a5-24a0-47cb-807d-60a0a2fe8114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from helper.analysis import JSON_FOLDER, get_dataset_from_json\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In colab!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCXnhgXNAON"
      },
      "source": [
        "## Experiments for the Ibsen corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdEa73lfCGXY"
      },
      "source": [
        "features_files = [\n",
        "    file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Ibsen\")\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noquTj4nWH1d"
      },
      "source": [
        "Experiments performing feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwMKE7KtAf7w"
      },
      "source": [
        "results_all_corpora = {}\n",
        "\n",
        "for corpus in [\"Ghosts\", \"Others\"]:\n",
        "\n",
        "    indexes = []  # file names as indices\n",
        "    cols = [\"Dimension\", \"SVC\", \"Naïve Bayes\", \"Decision Tree\", \"Logistic Regression\"]\n",
        "    results = []  # Where to hold the results per corpus\n",
        "\n",
        "    for file in [file for file in features_files if corpus in file.name]:\n",
        "\n",
        "        # Import data from JSON files\n",
        "        X_dict, y_str = get_dataset_from_json(file)\n",
        "\n",
        "        # Transformers to numpy arrays\n",
        "        dict_vect = DictVectorizer(sparse=True)\n",
        "        encoder = LabelEncoder()\n",
        "\n",
        "        # Numeric conversion\n",
        "        X = dict_vect.fit_transform(X_dict,)\n",
        "        y = encoder.fit_transform(y_str)\n",
        "\n",
        "        # Number of features\n",
        "        k = 18  # number of features to select\n",
        "        dimension = k  # comment out this line and uncomment next for full data set\n",
        "       # dimension = X.shape[1]\n",
        "\n",
        "        # K-fold to ingest cross-validation\n",
        "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "        # Models\n",
        "\n",
        "        ## SVM\n",
        "        svm_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"scaler\", StandardScaler(with_mean=False)),\n",
        "                (\"scv\", LinearSVC(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_svm = cross_val_score(svm_model, X, y, cv=kf)\n",
        "\n",
        "        ## Logistic regresssion\n",
        "        log_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"scaler\", StandardScaler(with_mean=False)),\n",
        "                (\"lrc\", LogisticRegression(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_log = cross_val_score(log_model, X, y, cv=kf)\n",
        "\n",
        "        ## Naïve Bayes\n",
        "        nb_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"nb\", MultinomialNB()),\n",
        "            ]\n",
        "        )\n",
        "        cv_nb = cross_val_score(nb_model, X, y, cv=kf)\n",
        "\n",
        "        ## Decision Tree\n",
        "        dt_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_dt = cross_val_score(dt_model, X, y, cv=kf)\n",
        "\n",
        "        # Results of cross-val for each feature set\n",
        "        result_per_featureset = [\n",
        "            dimension,\n",
        "            cv_svm.mean(),\n",
        "            cv_nb.mean(),\n",
        "            cv_dt.mean(),\n",
        "            cv_log.mean(),\n",
        "        ]\n",
        "\n",
        "        # Overall results for each author\n",
        "        results.append(result_per_featureset)\n",
        "        indexes.append(\" \".join(file.stem.split(\"_\")[2:]))  # features from file name\n",
        "\n",
        "    # All features for all authors\n",
        "    results_all_corpora[corpus] = pd.DataFrame(\n",
        "        np.array(results), index=indexes, columns=cols\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLROCvb5Af71"
      },
      "source": [
        "## Save results $\\LaTeX$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmr3iM0nNAOh",
        "outputId": "afc6b732-aa12-491d-9a34-3b33580665ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "results_all_corpora[\"Ghosts\"]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.695</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.770</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.915</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.955</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.980</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.955</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.810</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.955</td>\n",
              "      <td>0.955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.460</td>\n",
              "      <td>0.595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.380</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.535</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension    SVC  ...  Decision Tree  Logistic Regression\n",
              "syntactic n2          18.0  0.695  ...          0.680                0.715\n",
              "1grams punct          18.0  0.880  ...          0.650                0.920\n",
              "syntactic n3          18.0  0.580  ...          0.640                0.510\n",
              "3gramsPOS punct       18.0  1.000  ...          0.915                1.000\n",
              "cohesive punct        18.0  0.575  ...          0.635                0.615\n",
              "2grams punct          18.0  0.940  ...          0.955                0.980\n",
              "2grams                18.0  0.835  ...          0.720                0.815\n",
              "3grams punct          18.0  0.980  ...          0.955                1.000\n",
              "1grams                18.0  0.735  ...          0.590                0.815\n",
              "2gramsPOS punct       18.0  0.980  ...          0.955                0.955\n",
              "3grams                18.0  0.560  ...          0.470                0.555\n",
              "2gramsPOS             18.0  0.640  ...          0.460                0.595\n",
              "3gramsPOS             18.0  0.450  ...          0.365                0.380\n",
              "cohesive              18.0  0.535  ...          0.635                0.535\n",
              "\n",
              "[14 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoYiCXdNAOl",
        "outputId": "35f6588d-f565-4ec0-ebbe-56576376ab90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "results_all_corpora[\"Others\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.867647</td>\n",
              "      <td>0.872876</td>\n",
              "      <td>0.849346</td>\n",
              "      <td>0.878431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.918954</td>\n",
              "      <td>0.791830</td>\n",
              "      <td>0.872222</td>\n",
              "      <td>0.918954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.849020</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.836928</td>\n",
              "      <td>0.866993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.976797</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.849673</td>\n",
              "      <td>0.843791</td>\n",
              "      <td>0.843464</td>\n",
              "      <td>0.867320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.976471</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.890523</td>\n",
              "      <td>0.913399</td>\n",
              "      <td>0.803268</td>\n",
              "      <td>0.914052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.924183</td>\n",
              "      <td>0.935948</td>\n",
              "      <td>0.826797</td>\n",
              "      <td>0.947712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.888562</td>\n",
              "      <td>0.912418</td>\n",
              "      <td>0.797059</td>\n",
              "      <td>0.906209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.844118</td>\n",
              "      <td>0.774510</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.808497</td>\n",
              "      <td>0.803268</td>\n",
              "      <td>0.683987</td>\n",
              "      <td>0.808824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.723203</td>\n",
              "      <td>0.855556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  ...  Decision Tree  Logistic Regression\n",
              "syntactic n2          18.0  0.867647  ...       0.849346             0.878431\n",
              "1grams punct          18.0  0.918954  ...       0.872222             0.918954\n",
              "syntactic n3          18.0  0.849020  ...       0.836928             0.866993\n",
              "3grams punct          18.0  0.988235  ...       0.982680             0.988235\n",
              "2gramsPOS punct       18.0  0.994118  ...       0.976797             0.988235\n",
              "2grams punct          18.0  0.994118  ...       0.982680             0.994118\n",
              "cohesive punct        18.0  0.849673  ...       0.843464             0.867320\n",
              "3gramsPOS punct       18.0  0.994118  ...       0.988235             0.994118\n",
              "1grams                18.0  0.890523  ...       0.803268             0.914052\n",
              "2grams                18.0  0.924183  ...       0.826797             0.947712\n",
              "3grams                18.0  0.888562  ...       0.797059             0.906209\n",
              "2gramsPOS             18.0  0.850000  ...       0.774510             0.850000\n",
              "cohesive              18.0  0.808497  ...       0.683987             0.808824\n",
              "3gramsPOS             18.0  0.855556  ...       0.723203             0.855556\n",
              "\n",
              "[14 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ES4St_IAf76"
      },
      "source": [
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "for corpus in [\"Ghosts\", \"Others\"]:\n",
        "    df = results_all_corpora[corpus].sort_index()\n",
        "    \n",
        "    latex = df.to_latex(float_format=lambda x: '%.4f' % x)\n",
        "    with open(RESULTS_FOLDER/(corpus + \".tex\"), \"w\") as f:\n",
        "        f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dV9X8zJNAPE"
      },
      "source": [
        "## Mixed Corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhresNicNAPI"
      },
      "source": [
        "def run_all_classifiers(file_train: Path, file_test: Path, k: int = 18):\n",
        "\n",
        "    X_train_dict, y_train_str = get_dataset_from_json(file_train)\n",
        "    X_test_dict, y_test_str = get_dataset_from_json(file_test)\n",
        "\n",
        "    dict_vectorizer = DictVectorizer(sparse=True)\n",
        "    encoder = LabelEncoder()\n",
        "\n",
        "    X_train, y_train = (\n",
        "        dict_vectorizer.fit_transform(X_train_dict),\n",
        "        encoder.fit_transform(y_train_str),\n",
        "    )\n",
        "\n",
        "    X_test, y_test = (\n",
        "        dict_vectorizer.transform(X_test_dict),\n",
        "        encoder.transform(y_test_str),\n",
        "    )\n",
        "\n",
        "    # Shuffle\n",
        "    X_train_, y_train_ = shuffle(\n",
        "        X_train, y_train, random_state=24\n",
        "    )\n",
        "    # Models\n",
        "    svm_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"scv\", LinearSVC(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    log_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"lr\", LogisticRegression(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    nb_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"nb\", MultinomialNB()),\n",
        "        ])\n",
        "    \n",
        "    dt_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "        ]) \n",
        "    \n",
        "    \n",
        "\n",
        "    svm_model.fit(X_train_, y_train_)\n",
        "    log_model.fit(X_train_, y_train_)\n",
        "    nb_model.fit(X_train_, y_train_)\n",
        "    dt_model.fit(X_train_, y_train_)\n",
        "\n",
        "    return [\n",
        "        k,\n",
        "        accuracy_score(y_test, svm_model.predict(X_test)),\n",
        "        accuracy_score(y_test, log_model.predict(X_test)),\n",
        "        accuracy_score(y_test, nb_model.predict(X_test)),\n",
        "        accuracy_score(y_test, dt_model.predict(X_test)),\n",
        "    ]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhqVcZJ-NAPM"
      },
      "source": [
        "from helper.analysis import JSON_FOLDER, get_dataset_from_json\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from helper import ROOT\n",
        "\n",
        "features_files = [file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Ibsen\")]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZmmnvSddKeP",
        "outputId": "044d7d67-835a-4c7c-c5e8-00e9e8e76224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features_files"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_syntactic_n2.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_1grams_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_syntactic_n3.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_3gramsPOS_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_cohesive_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_2grams_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_2grams.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_3grams_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_1grams.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_2gramsPOS_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_3grams.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_2gramsPOS.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_3gramsPOS.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_cohesive.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_syntactic_n2.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_1grams_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_syntactic_n3.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_3grams_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_2gramsPOS_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_2grams_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_cohesive_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_3gramsPOS_punct.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_1grams.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_2grams.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_3grams.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_2gramsPOS.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_cohesive.json'),\n",
              " PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_3gramsPOS.json')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVl_Ny2NAPQ"
      },
      "source": [
        "ghosts = [file for file in features_files if \"Ghosts\" in file.stem]\n",
        "others = [file for file in features_files if not \"Ghosts\" in file.stem]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwYZKVe-NAPX"
      },
      "source": [
        "features = [(train, test) for train, test in zip(ghosts, others) if \" \".join(train.stem.split(\"_\")[2:]) == \" \".join(test.stem.split(\"_\")[2:])]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax64ComCdHQD",
        "outputId": "0e9ee19c-7526-4b7e-d30e-582a208fd96f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_syntactic_n2.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_syntactic_n2.json')),\n",
              " (PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_1grams_punct.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_1grams_punct.json')),\n",
              " (PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_syntactic_n3.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_syntactic_n3.json')),\n",
              " (PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_2grams_punct.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_2grams_punct.json')),\n",
              " (PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_1grams.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_1grams.json')),\n",
              " (PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_3grams.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_3grams.json')),\n",
              " (PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Ghosts_2gramsPOS.json'),\n",
              "  PosixPath('drive/My Drive/Translator-Attribution/auxfiles/json/Ibsen_Others_2gramsPOS.json'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOP8WGNsNAPb"
      },
      "source": [
        "columns = [\n",
        "    \"Dimension\",\n",
        "    \"SVC\",\n",
        "    \"Naïve Bayes\",\n",
        "    \"Decision Tree\",\n",
        "    \"Logistic Regression\",\n",
        "]\n",
        "\n",
        "indexes = [\" \".join(train.stem.split(\"_\")[2:]) for train, test in features]\n",
        "\n",
        "results_parallel = [run_all_classifiers(train, test) for train, test in features]\n",
        "results_parallel_df = pd.DataFrame(\n",
        "    np.array(results_parallel), index=indexes, columns=columns\n",
        ")\n",
        "\n",
        "results_inverse = [run_all_classifiers(train, test) for test, train in features]\n",
        "results_inverse_df = pd.DataFrame(\n",
        "    np.array(results_inverse), index=indexes, columns=columns\n",
        ")\n",
        "\n",
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "d = {\"parallel\": results_parallel_df, \"inverse\": results_inverse_df}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31cPrTwINAPe",
        "outputId": "a9040c88-63b1-418b-d152-9ea462c3ae79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "d[\"parallel\"]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.485549</td>\n",
              "      <td>0.526012</td>\n",
              "      <td>0.526012</td>\n",
              "      <td>0.508671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.606936</td>\n",
              "      <td>0.699422</td>\n",
              "      <td>0.867052</td>\n",
              "      <td>0.693642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.450867</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.421965</td>\n",
              "      <td>0.358382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.982659</td>\n",
              "      <td>0.965318</td>\n",
              "      <td>0.988439</td>\n",
              "      <td>0.797688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.653179</td>\n",
              "      <td>0.791908</td>\n",
              "      <td>0.745665</td>\n",
              "      <td>0.630058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.624277</td>\n",
              "      <td>0.630058</td>\n",
              "      <td>0.658960</td>\n",
              "      <td>0.572254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.664740</td>\n",
              "      <td>0.722543</td>\n",
              "      <td>0.739884</td>\n",
              "      <td>0.595376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Dimension       SVC  ...  Decision Tree  Logistic Regression\n",
              "syntactic n2       18.0  0.485549  ...       0.526012             0.508671\n",
              "1grams punct       18.0  0.606936  ...       0.867052             0.693642\n",
              "syntactic n3       18.0  0.450867  ...       0.421965             0.358382\n",
              "2grams punct       18.0  0.982659  ...       0.988439             0.797688\n",
              "1grams             18.0  0.653179  ...       0.745665             0.630058\n",
              "3grams             18.0  0.624277  ...       0.658960             0.572254\n",
              "2gramsPOS          18.0  0.664740  ...       0.739884             0.595376\n",
              "\n",
              "[7 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9za-Yh67NAPh",
        "outputId": "7abc1d35-9e0e-43b1-d635-ced5003da8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "d[\"inverse\"]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.612245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.693878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.530612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.836735</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.489796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.489796</td>\n",
              "      <td>0.489796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>18.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.612245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Dimension       SVC  ...  Decision Tree  Logistic Regression\n",
              "syntactic n2       18.0  0.571429  ...       0.571429             0.612245\n",
              "1grams punct       18.0  0.632653  ...       0.591837             0.693878\n",
              "syntactic n3       18.0  0.530612  ...       0.510204             0.530612\n",
              "2grams punct       18.0  0.897959  ...       0.897959             0.836735\n",
              "1grams             18.0  0.591837  ...       0.591837             0.489796\n",
              "3grams             18.0  0.469388  ...       0.489796             0.489796\n",
              "2gramsPOS          18.0  0.571429  ...       0.551020             0.612245\n",
              "\n",
              "[7 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ihGGWhGNAPl"
      },
      "source": [
        "for exp in d:\n",
        "    df = d[exp].sort_index()\n",
        "    \n",
        "    latex = df.to_latex(float_format=lambda x: \"%.4f\" % x)\n",
        "\n",
        "    with open((RESULTS_FOLDER / f\"{exp}.tex\"), \"w\") as f:\n",
        "        f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}