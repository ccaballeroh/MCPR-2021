{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03Experiments_Ibsen.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python [conda env:mcpr2021]",
      "language": "python",
      "name": "conda-env-mcpr2021-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccaballeroh/MCPR-2021/blob/main/03Experiments_Ibsen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDyOrAL_uaKE"
      },
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DHctFzuaKJ"
      },
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    ROOT = Path(r\"./drive/My Drive/Translator-Attribution\")\n",
        "    sys.path.insert(0,f\"{ROOT}/\")\n",
        "else:\n",
        "    from helper import ROOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BvwbPV7WH1Z"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05J6RsRnWH1a"
      },
      "source": [
        "## Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2HB1lIjAf7b"
      },
      "source": [
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from helper.analysis import JSON_FOLDER, get_dataset_from_json\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCXnhgXNAON"
      },
      "source": [
        "## Experiments for the Ibsen corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdEa73lfCGXY"
      },
      "source": [
        "features_files = [\n",
        "    file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Ibsen\")\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noquTj4nWH1d"
      },
      "source": [
        "Experiments performing feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwMKE7KtAf7w",
        "outputId": "120f57b6-2f77-40ae-caf1-6331df67746e"
      },
      "source": [
        "%%time\n",
        "results_all_corpora = {}\n",
        "\n",
        "for corpus in [\"Ghosts\", \"Others\"]:\n",
        "\n",
        "    indexes = []  # file names as indices\n",
        "    cols = [\"Dimension\", \"SVC\", \"Naïve Bayes\", \"Decision Tree\", \"Logistic Regression\"]\n",
        "    results = []  # Where to hold the results per corpus\n",
        "\n",
        "    for file in [file for file in features_files if corpus in file.name]:\n",
        "\n",
        "        # Import data from JSON files\n",
        "        X_dict, y_str = get_dataset_from_json(file)\n",
        "\n",
        "        # Transformers to numpy arrays\n",
        "        dict_vect = DictVectorizer(sparse=True)\n",
        "        encoder = LabelEncoder()\n",
        "\n",
        "        # Numeric conversion\n",
        "        X = dict_vect.fit_transform(X_dict,)\n",
        "        y = encoder.fit_transform(y_str)\n",
        "\n",
        "        # Number of features\n",
        "        k = 25  # number of features to select\n",
        "        dimension = k  # comment out this line and uncomment next for full data set\n",
        "       # dimension = X.shape[1]\n",
        "\n",
        "        # K-fold to ingest cross-validation\n",
        "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "        # Models\n",
        "\n",
        "        ## SVM\n",
        "        svm_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"scaler\", StandardScaler(with_mean=False)),\n",
        "                (\"scv\", LinearSVC(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_svm = cross_val_score(svm_model, X, y, cv=kf)\n",
        "\n",
        "        ## Logistic regresssion\n",
        "        log_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"scaler\", StandardScaler(with_mean=False)),\n",
        "                (\"lrc\", LogisticRegression(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_log = cross_val_score(log_model, X, y, cv=kf)\n",
        "\n",
        "        ## Naïve Bayes\n",
        "        nb_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"nb\", MultinomialNB()),\n",
        "            ]\n",
        "        )\n",
        "        cv_nb = cross_val_score(nb_model, X, y, cv=kf)\n",
        "\n",
        "        ## Decision Tree\n",
        "        dt_model = Pipeline(\n",
        "            [\n",
        "                (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "                (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "            ]\n",
        "        )\n",
        "        cv_dt = cross_val_score(dt_model, X, y, cv=kf)\n",
        "\n",
        "        # Results of cross-val for each feature set\n",
        "        result_per_featureset = [\n",
        "            dimension,\n",
        "            cv_svm.mean(),\n",
        "            cv_nb.mean(),\n",
        "            cv_dt.mean(),\n",
        "            cv_log.mean(),\n",
        "        ]\n",
        "\n",
        "        # Overall results for each author\n",
        "        results.append(result_per_featureset)\n",
        "        indexes.append(\" \".join(file.stem.split(\"_\")[2:]))  # features from file name\n",
        "\n",
        "    # All features for all authors\n",
        "    results_all_corpora[corpus] = pd.DataFrame(\n",
        "        np.array(results), index=indexes, columns=cols\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 2min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLROCvb5Af71"
      },
      "source": [
        "## Save results $\\LaTeX$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmr3iM0nNAOh",
        "outputId": "1d10a7d2-9ab9-4c10-bbcb-dc1ceefa0990"
      },
      "source": [
        "results_all_corpora[\"Ghosts\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.955</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.935</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.935</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.445</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension    SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.680        0.815          0.610   \n",
              "1grams punct          25.0  0.900        0.815          0.745   \n",
              "2grams                25.0  0.755        0.755          0.720   \n",
              "2gramsPOS             25.0  0.620        0.515          0.575   \n",
              "2gramsPOS punct       25.0  1.000        1.000          0.935   \n",
              "2grams punct          25.0  0.940        0.980          0.955   \n",
              "3grams                25.0  0.595        0.600          0.470   \n",
              "3gramsPOS             25.0  0.240        0.225          0.370   \n",
              "3gramsPOS punct       25.0  1.000        1.000          0.935   \n",
              "3grams punct          25.0  1.000        1.000          0.935   \n",
              "cohesive              25.0  0.475        0.615          0.610   \n",
              "cohesive punct        25.0  0.675        0.615          0.635   \n",
              "syntactic n2          25.0  0.445        0.565          0.835   \n",
              "syntactic n3          25.0  0.515        0.555          0.530   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                         0.840  \n",
              "1grams punct                   0.855  \n",
              "2grams                         0.780  \n",
              "2gramsPOS                      0.595  \n",
              "2gramsPOS punct                0.975  \n",
              "2grams punct                   0.980  \n",
              "3grams                         0.575  \n",
              "3gramsPOS                      0.280  \n",
              "3gramsPOS punct                1.000  \n",
              "3grams punct                   1.000  \n",
              "cohesive                       0.535  \n",
              "cohesive punct                 0.595  \n",
              "syntactic n2                   0.460  \n",
              "syntactic n3                   0.535  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoYiCXdNAOl",
        "outputId": "fd4d91da-0fe6-4f8e-c8b8-d1798c97dd37"
      },
      "source": [
        "results_all_corpora[\"Others\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.890523</td>\n",
              "      <td>0.919281</td>\n",
              "      <td>0.803268</td>\n",
              "      <td>0.902288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.918627</td>\n",
              "      <td>0.797712</td>\n",
              "      <td>0.866013</td>\n",
              "      <td>0.930392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.930719</td>\n",
              "      <td>0.931046</td>\n",
              "      <td>0.814706</td>\n",
              "      <td>0.942484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.838235</td>\n",
              "      <td>0.855882</td>\n",
              "      <td>0.728758</td>\n",
              "      <td>0.862092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.900980</td>\n",
              "      <td>0.907190</td>\n",
              "      <td>0.808497</td>\n",
              "      <td>0.894771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.873856</td>\n",
              "      <td>0.677451</td>\n",
              "      <td>0.838562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.959477</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.994118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.994118</td>\n",
              "      <td>0.982680</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.819608</td>\n",
              "      <td>0.832026</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.808497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.843464</td>\n",
              "      <td>0.849020</td>\n",
              "      <td>0.837255</td>\n",
              "      <td>0.890196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.889869</td>\n",
              "      <td>0.919281</td>\n",
              "      <td>0.814706</td>\n",
              "      <td>0.925163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.908170</td>\n",
              "      <td>0.925163</td>\n",
              "      <td>0.867320</td>\n",
              "      <td>0.924837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.890523     0.919281       0.803268   \n",
              "1grams punct          25.0  0.918627     0.797712       0.866013   \n",
              "2grams                25.0  0.930719     0.931046       0.814706   \n",
              "2gramsPOS             25.0  0.838235     0.855882       0.728758   \n",
              "2gramsPOS punct       25.0  0.988235     0.994118       0.982680   \n",
              "2grams punct          25.0  0.988235     0.994118       0.982680   \n",
              "3grams                25.0  0.900980     0.907190       0.808497   \n",
              "3gramsPOS             25.0  0.844444     0.873856       0.677451   \n",
              "3gramsPOS punct       25.0  0.994118     0.959477       0.970588   \n",
              "3grams punct          25.0  0.988235     0.994118       0.982680   \n",
              "cohesive              25.0  0.819608     0.832026       0.711111   \n",
              "cohesive punct        25.0  0.843464     0.849020       0.837255   \n",
              "syntactic n2          25.0  0.889869     0.919281       0.814706   \n",
              "syntactic n3          25.0  0.908170     0.925163       0.867320   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.902288  \n",
              "1grams punct                0.930392  \n",
              "2grams                      0.942484  \n",
              "2gramsPOS                   0.862092  \n",
              "2gramsPOS punct             0.994118  \n",
              "2grams punct                0.994118  \n",
              "3grams                      0.894771  \n",
              "3gramsPOS                   0.838562  \n",
              "3gramsPOS punct             0.994118  \n",
              "3grams punct                0.988235  \n",
              "cohesive                    0.808497  \n",
              "cohesive punct              0.890196  \n",
              "syntactic n2                0.925163  \n",
              "syntactic n3                0.924837  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ES4St_IAf76"
      },
      "source": [
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "for corpus in [\"Ghosts\", \"Others\"]:\n",
        "    df = results_all_corpora[corpus].sort_index()\n",
        "    \n",
        "    latex = df.to_latex(float_format=lambda x: '%.4f' % x)\n",
        "    with open(RESULTS_FOLDER/(corpus + \".tex\"), \"w\") as f:\n",
        "        f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dV9X8zJNAPE"
      },
      "source": [
        "## Mixed Corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhresNicNAPI"
      },
      "source": [
        "def run_all_classifiers(file_train: Path, file_test: Path, k: int = 25):\n",
        "\n",
        "    X_train_dict, y_train_str = get_dataset_from_json(file_train)\n",
        "    X_test_dict, y_test_str = get_dataset_from_json(file_test)\n",
        "\n",
        "    dict_vectorizer = DictVectorizer(sparse=True)\n",
        "    encoder = LabelEncoder()\n",
        "\n",
        "    X_train, y_train = (\n",
        "        dict_vectorizer.fit_transform(X_train_dict),\n",
        "        encoder.fit_transform(y_train_str),\n",
        "    )\n",
        "\n",
        "    X_test, y_test = (\n",
        "        dict_vectorizer.transform(X_test_dict),\n",
        "        encoder.transform(y_test_str),\n",
        "    )\n",
        "\n",
        "    # Shuffle\n",
        "    X_train_, y_train_ = shuffle(\n",
        "        X_train, y_train, random_state=24\n",
        "    )\n",
        "    # Models\n",
        "    svm_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"scv\", LinearSVC(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    log_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)),\n",
        "            (\"lr\", LogisticRegression(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    nb_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"nb\", MultinomialNB()),\n",
        "        ])\n",
        "    \n",
        "    dt_model = Pipeline(\n",
        "        [\n",
        "            (\"feat-sel\", SelectKBest(chi2, k=k)),\n",
        "            (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
        "        ]) \n",
        "    \n",
        "    \n",
        "\n",
        "    svm_model.fit(X_train_, y_train_)\n",
        "    log_model.fit(X_train_, y_train_)\n",
        "    nb_model.fit(X_train_, y_train_)\n",
        "    dt_model.fit(X_train_, y_train_)\n",
        "\n",
        "    return [\n",
        "        k,\n",
        "        accuracy_score(y_test, svm_model.predict(X_test)),\n",
        "        accuracy_score(y_test, log_model.predict(X_test)),\n",
        "        accuracy_score(y_test, nb_model.predict(X_test)),\n",
        "        accuracy_score(y_test, dt_model.predict(X_test)),\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhqVcZJ-NAPM"
      },
      "source": [
        "from helper.analysis import JSON_FOLDER, get_dataset_from_json\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from helper import ROOT\n",
        "\n",
        "features_files = [file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"Ibsen\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVl_Ny2NAPQ"
      },
      "source": [
        "ghosts = [file for file in features_files if \"Ghosts\" in file.stem]\n",
        "others = [file for file in features_files if not \"Ghosts\" in file.stem]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwYZKVe-NAPX"
      },
      "source": [
        "features = [(train, test) for train, test in zip(ghosts, others) if \" \".join(train.stem.split(\"_\")[2:]) == \" \".join(test.stem.split(\"_\")[2:])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOP8WGNsNAPb"
      },
      "source": [
        "columns = [\n",
        "    \"Dimension\",\n",
        "    \"SVC\",\n",
        "    \"Naïve Bayes\",\n",
        "    \"Decision Tree\",\n",
        "    \"Logistic Regression\",\n",
        "]\n",
        "\n",
        "indexes = [\" \".join(train.stem.split(\"_\")[2:]) for train, test in features]\n",
        "\n",
        "results_parallel = [run_all_classifiers(train, test) for train, test in features]\n",
        "results_parallel_df = pd.DataFrame(\n",
        "    np.array(results_parallel), index=indexes, columns=columns\n",
        ")\n",
        "\n",
        "results_inverse = [run_all_classifiers(train, test) for test, train in features]\n",
        "results_inverse_df = pd.DataFrame(\n",
        "    np.array(results_inverse), index=indexes, columns=columns\n",
        ")\n",
        "\n",
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "\n",
        "d = {\"parallel\": results_parallel_df, \"inverse\": results_inverse_df}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31cPrTwINAPe",
        "outputId": "01934704-7f80-45d9-88d4-4280a66a2cf7"
      },
      "source": [
        "d[\"parallel\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.664740</td>\n",
              "      <td>0.722543</td>\n",
              "      <td>0.780347</td>\n",
              "      <td>0.537572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.393064</td>\n",
              "      <td>0.439306</td>\n",
              "      <td>0.861272</td>\n",
              "      <td>0.653179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.554913</td>\n",
              "      <td>0.566474</td>\n",
              "      <td>0.606936</td>\n",
              "      <td>0.514451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.595376</td>\n",
              "      <td>0.670520</td>\n",
              "      <td>0.589595</td>\n",
              "      <td>0.664740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.947977</td>\n",
              "      <td>0.930636</td>\n",
              "      <td>0.959538</td>\n",
              "      <td>0.780347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.780347</td>\n",
              "      <td>0.774566</td>\n",
              "      <td>0.942197</td>\n",
              "      <td>0.797688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.630058</td>\n",
              "      <td>0.687861</td>\n",
              "      <td>0.653179</td>\n",
              "      <td>0.462428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.537572</td>\n",
              "      <td>0.537572</td>\n",
              "      <td>0.554913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.976879</td>\n",
              "      <td>0.971098</td>\n",
              "      <td>0.947977</td>\n",
              "      <td>0.791908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.942197</td>\n",
              "      <td>0.971098</td>\n",
              "      <td>0.988439</td>\n",
              "      <td>0.768786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.583815</td>\n",
              "      <td>0.572254</td>\n",
              "      <td>0.647399</td>\n",
              "      <td>0.578035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.595376</td>\n",
              "      <td>0.624277</td>\n",
              "      <td>0.618497</td>\n",
              "      <td>0.612717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.647399</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.589595</td>\n",
              "      <td>0.572254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.572254</td>\n",
              "      <td>0.572254</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.497110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.664740     0.722543       0.780347   \n",
              "1grams punct          25.0  0.393064     0.439306       0.861272   \n",
              "2grams                25.0  0.554913     0.566474       0.606936   \n",
              "2gramsPOS             25.0  0.595376     0.670520       0.589595   \n",
              "2gramsPOS punct       25.0  0.947977     0.930636       0.959538   \n",
              "2grams punct          25.0  0.780347     0.774566       0.942197   \n",
              "3grams                25.0  0.630058     0.687861       0.653179   \n",
              "3gramsPOS             25.0  0.531792     0.537572       0.537572   \n",
              "3gramsPOS punct       25.0  0.976879     0.971098       0.947977   \n",
              "3grams punct          25.0  0.942197     0.971098       0.988439   \n",
              "cohesive              25.0  0.583815     0.572254       0.647399   \n",
              "cohesive punct        25.0  0.595376     0.624277       0.618497   \n",
              "syntactic n2          25.0  0.647399     0.641618       0.589595   \n",
              "syntactic n3          25.0  0.572254     0.572254       0.531792   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.537572  \n",
              "1grams punct                0.653179  \n",
              "2grams                      0.514451  \n",
              "2gramsPOS                   0.664740  \n",
              "2gramsPOS punct             0.780347  \n",
              "2grams punct                0.797688  \n",
              "3grams                      0.462428  \n",
              "3gramsPOS                   0.554913  \n",
              "3gramsPOS punct             0.791908  \n",
              "3grams punct                0.768786  \n",
              "cohesive                    0.578035  \n",
              "cohesive punct              0.612717  \n",
              "syntactic n2                0.572254  \n",
              "syntactic n3                0.497110  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9za-Yh67NAPh",
        "outputId": "1d77ef07-791b-4dd8-e9e1-110f13fc6b63"
      },
      "source": [
        "d[\"inverse\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dimension</th>\n",
              "      <th>SVC</th>\n",
              "      <th>Naïve Bayes</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.653061</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.612245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.653061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.510204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.979592</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.469388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3gramsPOS punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.816327</td>\n",
              "      <td>0.836735</td>\n",
              "      <td>0.959184</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3grams punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.632653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cohesive punct</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.591837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>syntactic n3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.551020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Dimension       SVC  Naïve Bayes  Decision Tree  \\\n",
              "1grams                25.0  0.632653     0.653061       0.551020   \n",
              "1grams punct          25.0  0.632653     0.612245       0.612245   \n",
              "2grams                25.0  0.734694     0.734694       0.591837   \n",
              "2gramsPOS             25.0  0.591837     0.591837       0.571429   \n",
              "2gramsPOS punct       25.0  0.877551     0.877551       0.979592   \n",
              "2grams punct          25.0  0.918367     0.857143       0.897959   \n",
              "3grams                25.0  0.530612     0.530612       0.510204   \n",
              "3gramsPOS             25.0  0.591837     0.551020       0.551020   \n",
              "3gramsPOS punct       25.0  0.816327     0.836735       0.959184   \n",
              "3grams punct          25.0  0.897959     0.877551       0.918367   \n",
              "cohesive              25.0  0.551020     0.551020       0.591837   \n",
              "cohesive punct        25.0  0.571429     0.571429       0.612245   \n",
              "syntactic n2          25.0  0.612245     0.571429       0.551020   \n",
              "syntactic n3          25.0  0.612245     0.591837       0.571429   \n",
              "\n",
              "                 Logistic Regression  \n",
              "1grams                      0.612245  \n",
              "1grams punct                0.653061  \n",
              "2grams                      0.571429  \n",
              "2gramsPOS                   0.510204  \n",
              "2gramsPOS punct             0.836735  \n",
              "2grams punct                0.836735  \n",
              "3grams                      0.428571  \n",
              "3gramsPOS                   0.469388  \n",
              "3gramsPOS punct             1.000000  \n",
              "3grams punct                0.836735  \n",
              "cohesive                    0.632653  \n",
              "cohesive punct              0.571429  \n",
              "syntactic n2                0.591837  \n",
              "syntactic n3                0.551020  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ihGGWhGNAPl"
      },
      "source": [
        "for exp in d:\n",
        "    df = d[exp].sort_index()\n",
        "    \n",
        "    latex = df.to_latex(float_format=lambda x: \"%.4f\" % x)\n",
        "\n",
        "    with open((RESULTS_FOLDER / f\"{exp}.tex\"), \"w\") as f:\n",
        "        f.write(latex)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}